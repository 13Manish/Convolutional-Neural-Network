{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO ModelTraining 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SXvu-Zo0Z2aaKigctueV5fVhrfrUbzv1",
      "authorship_tag": "ABX9TyOL93JoE8nTmwartGgJGuYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish284/Convolutional-Neural-Network/blob/master/YOLO_ModelTraining_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hyFuMgahyEi",
        "outputId": "2d457da3-13a2-469f-cd6e-6ebd6668d01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpOU2Z89Sqwj"
      },
      "source": [
        "#!pip install tensorflow-gpu==1.15.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA3f_MHZGNZe",
        "outputId": "cfa6b636-cb11-4206-f852-c17b6001e390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-1d3dZagG9o"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab/DL/yad2k')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjtTGejbHBjF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QYbc4czgHXg",
        "outputId": "b423f161-531a-4ffe-c29b-744d2f9c01ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import argparse\n",
        "\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Lambda, Conv2D\n",
        "from keras.models import load_model, Model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMWYgO-fQ1WT"
      },
      "source": [
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class CustomTensorBoard(TensorBoard):\n",
        "    \"\"\" to log the loss after each batch\n",
        "    \"\"\"    \n",
        "    def __init__(self, log_every=1, **kwargs):\n",
        "        super(CustomTensorBoard, self).__init__(**kwargs)\n",
        "        self.log_every = log_every\n",
        "        self.counter = 0\n",
        "    \n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.counter+=1\n",
        "        if self.counter%self.log_every==0:\n",
        "            for name, value in logs.items():\n",
        "                if name in ['batch', 'size']:\n",
        "                    continue\n",
        "                summary = tf.Summary()\n",
        "                summary_value = summary.value.add()\n",
        "                summary_value.simple_value = value.item()\n",
        "                summary_value.tag = name\n",
        "                self.writer.add_summary(summary, self.counter)\n",
        "            self.writer.flush()\n",
        "        \n",
        "        super(CustomTensorBoard, self).on_batch_end(batch, logs)\n",
        "\n",
        "class CustomModelCheckpoint(ModelCheckpoint):\n",
        "    \"\"\" to save the template model, not the multi-GPU model\n",
        "    \"\"\"\n",
        "    def __init__(self, model_to_save, **kwargs):\n",
        "        super(CustomModelCheckpoint, self).__init__(**kwargs)\n",
        "        self.model_to_save = model_to_save\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.epochs_since_last_save += 1\n",
        "        if self.epochs_since_last_save >= self.period:\n",
        "            self.epochs_since_last_save = 0\n",
        "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
        "            if self.save_best_only:\n",
        "                current = logs.get(self.monitor)\n",
        "                if current is None:\n",
        "                    warnings.warn('Can save best model only with %s available, '\n",
        "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
        "                else:\n",
        "                    if self.monitor_op(current, self.best):\n",
        "                        if self.verbose > 0:\n",
        "                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
        "                                  ' saving model to %s'\n",
        "                                  % (epoch + 1, self.monitor, self.best,\n",
        "                                     current, filepath))\n",
        "                        self.best = current\n",
        "                        if self.save_weights_only:\n",
        "                            self.model_to_save.save_weights(filepath, overwrite=True)\n",
        "                        else:\n",
        "                            self.model_to_save.save(filepath, overwrite=True)\n",
        "                    else:\n",
        "                        if self.verbose > 0:\n",
        "                            print('\\nEpoch %05d: %s did not improve from %0.5f' %\n",
        "                                  (epoch + 1, self.monitor, self.best))\n",
        "            else:\n",
        "                if self.verbose > 0:\n",
        "                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
        "                if self.save_weights_only:\n",
        "                    self.model_to_save.save_weights(filepath, overwrite=True)\n",
        "                else:\n",
        "                    self.model_to_save.save(filepath, overwrite=True)\n",
        "\n",
        "        super(CustomModelCheckpoint, self).on_batch_end(epoch, logs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFBGHjSGK7s"
      },
      "source": [
        "config = tf.compat.v1.ConfigProto(\n",
        "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
        "    # device_count = {'GPU': 1}\n",
        ")\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "tf.compat.v1.keras.backend.set_session(session)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7H79nrd8A4y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRuZoUOOfc9f"
      },
      "source": [
        "from yad2k.models.keras_yolo import (preprocess_true_boxes, yolo_body,\n",
        "                                     yolo_eval, yolo_head, yolo_loss)\n",
        "from yad2k.utils.draw_boxes import draw_boxes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fukn307KftyO"
      },
      "source": [
        "model_data_path ='/content/drive/My Drive/Colab/DL/yad2k/model_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLBSQLwmgkS_"
      },
      "source": [
        "data_path = os.path.join(model_data_path,'data_train.txt')\n",
        "classes_path = os.path.join(model_data_path,'object_classes.txt')\n",
        "anchors_path = os.path.join(model_data_path,'yolo_anchors.txt')\n",
        "weight_path = os.path.join(model_data_path,'yolo.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTZD-xz3iUnf"
      },
      "source": [
        "YOLO_ANCHORS = np.array(\n",
        "    ((0.57273, 0.677385), (1.87446, 2.06253), (3.33843, 5.47434),\n",
        "     (7.88282, 3.52778), (9.77052, 9.16828)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRudhL_iRqL"
      },
      "source": [
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    if os.path.isfile(anchors_path):\n",
        "        with open(anchors_path) as f:\n",
        "            anchors = f.readline()\n",
        "            anchors = [float(x) for x in anchors.split(',')]\n",
        "            return np.array(anchors).reshape(-1, 2)\n",
        "    else:\n",
        "        Warning(\"Could not open anchors file, using default.\")\n",
        "        return YOLO_ANCHORS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68JHBr97h4Ji"
      },
      "source": [
        "class_names = get_classes(classes_path)\n",
        "anchors = get_anchors(anchors_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhrVaWPZiEGq"
      },
      "source": [
        "anchors = YOLO_ANCHORS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhTnf8Xri91w"
      },
      "source": [
        "with open(data_path) as f:\n",
        "  data = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aua0JWxljH9X"
      },
      "source": [
        "def get_images_boxes(data):\n",
        "  images = []\n",
        "  boxes = []\n",
        "  for annotation_line in data:\n",
        "    tmp_split = re.split(\"( \\d)\", annotation_line, maxsplit=1)\n",
        "    if len(tmp_split) > 2:\n",
        "        line = tmp_split[0], tmp_split[1] + tmp_split[2]\n",
        "    else:\n",
        "        line = tmp_split\n",
        "\n",
        "    image = Image.open(line[0])\n",
        "    image = np.asarray(image)\n",
        "    line = line[1].split(\" \")\n",
        "    box = np.array([np.array(list(map(int, box.split(\",\")))) for box in line[1:]])\n",
        "    images.append(image)\n",
        "    boxes.append(box)\n",
        "  return images, np.array(boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW8S5jFVlZLy"
      },
      "source": [
        "\n",
        "def process_data(images, boxes=None):\n",
        "    '''processes the data'''\n",
        "    images = [PIL.Image.fromarray(i) for i in images]\n",
        "    orig_size = np.array([images[0].width, images[0].height])\n",
        "    orig_size = np.expand_dims(orig_size, axis=0)\n",
        "\n",
        "    # Image preprocessing.\n",
        "    processed_images = [i.resize((416, 416), PIL.Image.BICUBIC) for i in images]\n",
        "    processed_images = [np.array(image, dtype=np.float) for image in processed_images]\n",
        "    processed_images = [image/255. for image in processed_images]\n",
        "\n",
        "    if boxes is not None:\n",
        "        # Box preprocessing.\n",
        "        # Original boxes stored as 1D list of class, x_min, y_min, x_max, y_max.\n",
        "        boxes = [box.reshape((-1, 5)) for box in boxes]\n",
        "        # Get extents as y_min, x_min, y_max, x_max, class for comparision with\n",
        "        # model output.\n",
        "        boxes_extents = [box[:, [2, 1, 4, 3, 0]] for box in boxes]\n",
        "\n",
        "        # Get box parameters as x_center, y_center, box_width, box_height, class.\n",
        "        boxes_xy = [0.5 * (box[:, 3:5] + box[:, 1:3]) for box in boxes]\n",
        "        boxes_wh = [box[:, 3:5] - box[:, 1:3] for box in boxes]\n",
        "        boxes_xy = [boxxy / orig_size for boxxy in boxes_xy]\n",
        "        boxes_wh = [boxwh / orig_size for boxwh in boxes_wh]\n",
        "        boxes = [np.concatenate((boxes_xy[i], boxes_wh[i], box[:, 0:1]), axis=1) for i, box in enumerate(boxes)]\n",
        "\n",
        "        # find the max number of boxes\n",
        "        max_boxes = 0\n",
        "        for boxz in boxes:\n",
        "            if boxz.shape[0] > max_boxes:\n",
        "                max_boxes = boxz.shape[0]\n",
        "\n",
        "        # add zero pad for training\n",
        "        for i, boxz in enumerate(boxes):\n",
        "            if boxz.shape[0]  < max_boxes:\n",
        "                zero_padding = np.zeros( (max_boxes-boxz.shape[0], 5), dtype=np.float32)\n",
        "                boxes[i] = np.vstack((boxz, zero_padding))\n",
        "\n",
        "        return np.array(processed_images), np.array(boxes)\n",
        "    else:\n",
        "        return np.array(processed_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "subguXf7sxdB"
      },
      "source": [
        "def get_detector_mask(boxes, anchors):\n",
        "    '''\n",
        "    Precompute detectors_mask and matching_true_boxes for training.\n",
        "    Detectors mask is 1 for each spatial position in the final conv layer and\n",
        "    anchor that should be active for the given boxes and 0 otherwise.\n",
        "    Matching true boxes gives the regression targets for the ground truth box\n",
        "    that caused a detector to be active or 0 otherwise.\n",
        "    '''\n",
        "    detectors_mask = [0 for i in range(len(boxes))]\n",
        "    matching_true_boxes = [0 for i in range(len(boxes))]\n",
        "    for i, box in enumerate(boxes):\n",
        "        detectors_mask[i], matching_true_boxes[i] = preprocess_true_boxes(box, anchors, [416, 416])\n",
        "\n",
        "    return np.array(detectors_mask), np.array(matching_true_boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EsX-qVMr_yv"
      },
      "source": [
        "images, boxes =get_images_boxes(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXD5JvO8kZ1w"
      },
      "source": [
        "image_data, boxes = process_data(images,boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59AgwG4LsRmi"
      },
      "source": [
        "detectors_mask, matching_true_boxes = get_detector_mask(boxes, anchors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3jqOWfzrAIu"
      },
      "source": [
        "def create_model(anchors, class_names, load_pretrained=True, freeze_body=True):\n",
        "    '''\n",
        "    returns the body of the model and the model\n",
        "    # Params:\n",
        "    load_pretrained: whether or not to load the pretrained model or initialize all weights\n",
        "    freeze_body: whether or not to freeze all weights except for the last layer's\n",
        "    # Returns:\n",
        "    model_body: YOLOv2 with new output layer\n",
        "    model: YOLOv2 with custom loss Lambda layer\n",
        "    '''\n",
        "\n",
        "    detectors_mask_shape = (13, 13, 5, 1)\n",
        "    matching_boxes_shape = (13, 13, 5, 5)\n",
        "\n",
        "    # Create model input layers.\n",
        "    image_input = Input(shape=(416, 416, 3))\n",
        "    boxes_input = Input(shape=(None, 5))\n",
        "    detectors_mask_input = Input(shape=detectors_mask_shape)\n",
        "    matching_boxes_input = Input(shape=matching_boxes_shape)\n",
        "\n",
        "    # Create model body.\n",
        "    yolo_model = yolo_body(image_input, len(anchors), len(class_names))\n",
        "    topless_yolo = Model(yolo_model.input, yolo_model.layers[-2].output)\n",
        "\n",
        "    if load_pretrained:\n",
        "        # Save topless yolo:\n",
        "        topless_yolo_path = os.path.join('model_data', 'yolo_topless.h5')\n",
        "        if not os.path.exists(topless_yolo_path):\n",
        "            print(\"CREATING TOPLESS WEIGHTS FILE\")\n",
        "            yolo_path = os.path.join('model_data', 'yolo.h5')\n",
        "            model_body = load_model(yolo_path)\n",
        "            model_body = Model(model_body.inputs, model_body.layers[-2].output)\n",
        "            model_body.save_weights(topless_yolo_path)\n",
        "        topless_yolo.load_weights(topless_yolo_path, by_name=True, skip_mismatch=True)\n",
        "\n",
        "    if freeze_body:\n",
        "        for layer in topless_yolo.layers:\n",
        "            layer.trainable = False\n",
        "    final_layer = Conv2D(len(anchors)*(5+len(class_names)), (1, 1), activation='linear')(topless_yolo.output)\n",
        "\n",
        "    model_body = Model(image_input, final_layer)\n",
        "\n",
        "    # Place model loss on CPU to reduce GPU memory usage.\n",
        "    with tf.device('/cpu:0'):\n",
        "        # TODO: Replace Lambda with custom Keras layer for loss.\n",
        "        model_loss = Lambda(\n",
        "            yolo_loss,\n",
        "            output_shape=(1, ),\n",
        "            name='yolo_loss',\n",
        "            arguments={'anchors': anchors,\n",
        "                       'num_classes': len(class_names)})([\n",
        "                           model_body.output, boxes_input,\n",
        "                           detectors_mask_input, matching_boxes_input\n",
        "                       ])\n",
        "\n",
        "    model = Model(\n",
        "        [model_body.input, boxes_input, detectors_mask_input,\n",
        "         matching_boxes_input], model_loss)\n",
        "\n",
        "    return model_body, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvXNvnktuuH5",
        "outputId": "ee5a7d82-a475-49b1-ff98-10c4e44f2c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " model_body, model = create_model(anchors, class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Colab/DL/yad2k/yad2k/models/keras_yolo.py:31: The name tf.space_to_depth is deprecated. Please use tf.compat.v1.space_to_depth instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_3 due to mismatch in shape ((3, 3, 64, 128) vs (32, 64, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_3 due to mismatch in shape ((128,) vs (32,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_4 due to mismatch in shape ((1, 1, 128, 64) vs (64, 32, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_6 due to mismatch in shape ((3, 3, 128, 256) vs (64, 128, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_6 due to mismatch in shape ((256,) vs (64,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_7 due to mismatch in shape ((1, 1, 256, 128) vs (128, 64, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_8 due to mismatch in shape ((3, 3, 128, 256) vs (64, 128, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_8 due to mismatch in shape ((256,) vs (64,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_9 due to mismatch in shape ((3, 3, 256, 512) vs (128, 64, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_9 due to mismatch in shape ((512,) vs (128,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_10 due to mismatch in shape ((1, 1, 512, 256) vs (256, 128, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_11 due to mismatch in shape ((3, 3, 256, 512) vs (128, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_11 due to mismatch in shape ((512,) vs (128,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_12 due to mismatch in shape ((1, 1, 512, 256) vs (256, 128, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_13 due to mismatch in shape ((3, 3, 256, 512) vs (128, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_13 due to mismatch in shape ((512,) vs (128,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_14 due to mismatch in shape ((3, 3, 512, 1024) vs (256, 128, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_14 due to mismatch in shape ((1024,) vs (256,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_15 due to mismatch in shape ((1, 1, 1024, 512) vs (128, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_15 due to mismatch in shape ((512,) vs (128,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_16 due to mismatch in shape ((3, 3, 512, 1024) vs (256, 128, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_16 due to mismatch in shape ((1024,) vs (256,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_17 due to mismatch in shape ((1, 1, 1024, 512) vs (128, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_17 due to mismatch in shape ((512,) vs (128,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_18 due to mismatch in shape ((3, 3, 512, 1024) vs (256, 128, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_18 due to mismatch in shape ((1024,) vs (256,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_19 due to mismatch in shape ((3, 3, 1024, 1024) vs (128, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_19 due to mismatch in shape ((1024,) vs (128,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_20 due to mismatch in shape ((3, 3, 1024, 1024) vs (256, 128, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_20 due to mismatch in shape ((1024,) vs (256,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_21 due to mismatch in shape ((1, 1, 512, 64) vs (128, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_21 due to mismatch in shape ((64,) vs (128,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_22 due to mismatch in shape ((3, 3, 1280, 1024) vs (256, 128, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer batch_normalization_22 due to mismatch in shape ((1024,) vs (256,)).\n",
            "  weight_values[i].shape))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYQyD79ruyOH"
      },
      "source": [
        "\n",
        "#model_body.summay()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v89lOmZo57Fs",
        "outputId": "d3233200-c855-49cb-aafc-253e6265325a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 416, 416, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 416, 416, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 208, 208, 32) 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 208, 208, 64) 18432       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 208, 208, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 104, 104, 128 73728       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 104, 104, 128 512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 104, 104, 64) 8192        leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 104, 104, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 104, 104, 128 73728       leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 104, 104, 128 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 52, 52, 256)  294912      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 52, 52, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 52, 52, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 52, 52, 128)  32768       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 52, 52, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 52, 52, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 52, 52, 256)  294912      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 52, 52, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 52, 52, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 26, 26, 512)  1179648     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 26, 26, 512)  2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 512)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 26, 26, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 26, 26, 512)  2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 26, 26, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 26, 26, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 13, 13, 1024) 4718592     max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 13, 13, 1024) 4096        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 13, 13, 512)  2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 13, 13, 1024) 4096        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 13, 13, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 13, 13, 1024) 4096        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 13, 13, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 13, 13, 1024) 4096        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 26, 26, 64)   32768       leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 26, 26, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 13, 13, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 26, 26, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 13, 13, 1024) 4096        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "space_to_depth (Lambda)         (None, 13, 13, 256)  0           leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 13, 13, 1280) 0           space_to_depth[0][0]             \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 13, 13, 1024) 11796480    concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 13, 13, 1024) 4096        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 13, 13, 30)   30750       leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None, 5)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 13, 13, 5, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 13, 13, 5, 5) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_loss (Lambda)              (None, 1)            0           conv2d_24[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 50,578,686\n",
            "Trainable params: 30,750\n",
            "Non-trainable params: 50,547,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOlbkSPebEDT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYVtfPn169HU"
      },
      "source": [
        "def train(model, class_names, anchors, image_data, boxes, detectors_mask, matching_true_boxes, validation_split=0.1):\n",
        "    '''\n",
        "    retrain/fine-tune the model\n",
        "    logs training with tensorboard\n",
        "    saves training weights in current directory\n",
        "    best weights according to val_loss is saved as trained_stage_3_best.h5\n",
        "    '''\n",
        "    model.compile(\n",
        "        optimizer='adam', loss={\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred\n",
        "        })  # This is a hack to use the custom loss function in the last layer.\n",
        "\n",
        "\n",
        "    logging = TensorBoard()\n",
        "    checkpoint = ModelCheckpoint(\"trained_stage_3_best.h5\", monitor='val_loss',\n",
        "                                 save_weights_only=True, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
        "\n",
        "    model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
        "              np.zeros(len(image_data)),\n",
        "              validation_split=validation_split,\n",
        "              batch_size=32,\n",
        "              epochs=5,\n",
        "              callbacks=[logging])\n",
        "    model.save_weights('trained_stage_1.h5')\n",
        "\n",
        "    #model_body, model = create_model(anchors, class_names, load_pretrained=False, freeze_body=False)\n",
        "\n",
        "    model.load_weights('trained_stage_1.h5')\n",
        "\n",
        "    '''model.compile(\n",
        "        optimizer='adam', loss={\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred\n",
        "        })  # This is a hack to use the custom loss function in the last layer.'''\n",
        "\n",
        "\n",
        "    model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
        "              np.zeros(len(image_data)),\n",
        "              validation_split=0.1,\n",
        "              batch_size=8,\n",
        "              epochs=30,\n",
        "              callbacks=[logging])\n",
        "\n",
        "    model.save_weights('trained_stage_2.h5')\n",
        "\n",
        "    model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
        "              np.zeros(len(image_data)),\n",
        "              validation_split=0.1,\n",
        "              batch_size=8,\n",
        "              epochs=30,\n",
        "              callbacks=[logging, checkpoint, early_stopping])\n",
        "\n",
        "    model.save_weights('trained_stage_3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeFR8kLN6-H6",
        "outputId": "26ed9723-18ac-4776-bd26-3ad43ab1c412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(model,\n",
        "        class_names,\n",
        "        anchors,\n",
        "        image_data,\n",
        "        boxes,\n",
        "        detectors_mask,\n",
        "        matching_true_boxes\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 90 samples, validate on 10 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/5\n",
            "90/90 [==============================] - 13s 146ms/step - loss: 711554.5795 - val_loss: 1399.1074\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/5\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 18468.3555 - val_loss: 1261.2407\n",
            "Epoch 3/5\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 3279.7859 - val_loss: 1174.0327\n",
            "Epoch 4/5\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 12363.1104 - val_loss: 1114.5250\n",
            "Epoch 5/5\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 1406.0782 - val_loss: 1072.1085\n",
            "Train on 90 samples, validate on 10 samples\n",
            "Epoch 1/30\n",
            "90/90 [==============================] - 3s 33ms/step - loss: 251.8263 - val_loss: 674.3959\n",
            "Epoch 2/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 187.7708 - val_loss: 656.5454\n",
            "Epoch 3/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 178.0124 - val_loss: 650.3562\n",
            "Epoch 4/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 165.9273 - val_loss: 647.8741\n",
            "Epoch 5/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 168.7049 - val_loss: 646.5484\n",
            "Epoch 6/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 165.8981 - val_loss: 645.5573\n",
            "Epoch 7/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 158.1454 - val_loss: 644.6471\n",
            "Epoch 8/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 158.6764 - val_loss: 643.7432\n",
            "Epoch 9/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 157.8264 - val_loss: 642.8143\n",
            "Epoch 10/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 155.5183 - val_loss: 641.8466\n",
            "Epoch 11/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 154.4984 - val_loss: 640.8720\n",
            "Epoch 12/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 150.8942 - val_loss: 639.8762\n",
            "Epoch 13/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 150.1431 - val_loss: 638.8871\n",
            "Epoch 14/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 145.2725 - val_loss: 637.8580\n",
            "Epoch 15/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 141.2758 - val_loss: 636.8436\n",
            "Epoch 16/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 139.7005 - val_loss: 635.8242\n",
            "Epoch 17/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 140.7280 - val_loss: 634.8032\n",
            "Epoch 18/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 138.7225 - val_loss: 633.7849\n",
            "Epoch 19/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 134.2249 - val_loss: 632.7684\n",
            "Epoch 20/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 134.2904 - val_loss: 631.7191\n",
            "Epoch 21/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 137.6700 - val_loss: 630.6850\n",
            "Epoch 22/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 131.2676 - val_loss: 629.6491\n",
            "Epoch 23/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 129.1398 - val_loss: 628.6357\n",
            "Epoch 24/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 131.4456 - val_loss: 627.6261\n",
            "Epoch 25/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 125.0602 - val_loss: 626.6191\n",
            "Epoch 26/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 120.8914 - val_loss: 625.6345\n",
            "Epoch 27/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 122.0398 - val_loss: 624.6466\n",
            "Epoch 28/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 117.1433 - val_loss: 623.6755\n",
            "Epoch 29/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 118.8633 - val_loss: 622.6922\n",
            "Epoch 30/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 115.1577 - val_loss: 621.7081\n",
            "Train on 90 samples, validate on 10 samples\n",
            "Epoch 1/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 114.6049 - val_loss: 620.7438\n",
            "Epoch 2/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 115.3035 - val_loss: 619.7853\n",
            "Epoch 3/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 111.6352 - val_loss: 618.8183\n",
            "Epoch 4/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 113.6988 - val_loss: 617.8694\n",
            "Epoch 5/30\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 111.0033 - val_loss: 616.9229\n",
            "Epoch 6/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 106.6090 - val_loss: 615.9808\n",
            "Epoch 7/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 104.6865 - val_loss: 615.0549\n",
            "Epoch 8/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 104.2196 - val_loss: 614.1477\n",
            "Epoch 9/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 102.3115 - val_loss: 613.2375\n",
            "Epoch 10/30\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 98.8222 - val_loss: 612.3526\n",
            "Epoch 11/30\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 98.8831 - val_loss: 611.4723\n",
            "Epoch 12/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 95.0917 - val_loss: 610.6050\n",
            "Epoch 13/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 99.3828 - val_loss: 609.7347\n",
            "Epoch 14/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 92.8228 - val_loss: 608.8620\n",
            "Epoch 15/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 92.3931 - val_loss: 608.0108\n",
            "Epoch 16/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 96.1013 - val_loss: 607.1477\n",
            "Epoch 17/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 92.7133 - val_loss: 606.2954\n",
            "Epoch 18/30\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 89.4991 - val_loss: 605.4454\n",
            "Epoch 19/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 87.1258 - val_loss: 604.6198\n",
            "Epoch 20/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 86.7465 - val_loss: 603.7764\n",
            "Epoch 21/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 86.0146 - val_loss: 602.9596\n",
            "Epoch 22/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 85.6717 - val_loss: 602.1546\n",
            "Epoch 23/30\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 84.3751 - val_loss: 601.3609\n",
            "Epoch 24/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 83.6963 - val_loss: 600.5502\n",
            "Epoch 25/30\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 81.6322 - val_loss: 599.7553\n",
            "Epoch 26/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 80.8316 - val_loss: 598.9826\n",
            "Epoch 27/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 80.9948 - val_loss: 598.2035\n",
            "Epoch 28/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 80.3012 - val_loss: 597.4163\n",
            "Epoch 29/30\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 77.6185 - val_loss: 596.6566\n",
            "Epoch 30/30\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 77.5632 - val_loss: 595.8905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4rgHVWR6SV",
        "outputId": "94be7651-459b-4842-9e2c-8938351125e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_body.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 416, 416, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 416, 416, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 208, 208, 32) 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 208, 208, 64) 18432       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 208, 208, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 104, 104, 128 73728       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 104, 104, 128 512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 104, 104, 64) 8192        leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 104, 104, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 104, 104, 128 73728       leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 104, 104, 128 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 52, 52, 256)  294912      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 52, 52, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 52, 52, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 52, 52, 128)  32768       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 52, 52, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 52, 52, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 52, 52, 256)  294912      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 52, 52, 256)  1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 52, 52, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 26, 26, 512)  1179648     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 26, 26, 512)  2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 512)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 26, 26, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 26, 26, 512)  2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 26, 26, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 26, 26, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 13, 13, 1024) 4718592     max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 13, 13, 1024) 4096        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 13, 13, 512)  2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 13, 13, 1024) 4096        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 13, 13, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 13, 13, 1024) 4096        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 13, 13, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 13, 13, 1024) 4096        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 26, 26, 64)   32768       leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 26, 26, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 13, 13, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 26, 26, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 13, 13, 1024) 4096        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "space_to_depth (Lambda)         (None, 13, 13, 256)  0           leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 13, 13, 1280) 0           space_to_depth[0][0]             \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 13, 13, 1024) 11796480    concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 13, 13, 1024) 4096        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 13, 13, 30)   30750       leaky_re_lu_22[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 50,578,686\n",
            "Trainable params: 30,750\n",
            "Non-trainable params: 50,547,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMglgpg2VzqP"
      },
      "source": [
        "model_body.load_weights('/content/drive/My Drive/Colab/DL/yad2k/trained_stage_3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40bRBLLFWGOo"
      },
      "source": [
        "model_body.save('/content/drive/My Drive/Colab/DL/yad2k/model_data/Model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSMH6eiPWM0f",
        "outputId": "7a9d6a35-8145-4fb6-d479-78f46f8199be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_body.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'conv2d_24/BiasAdd:0' shape=(?, 13, 13, 30) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}